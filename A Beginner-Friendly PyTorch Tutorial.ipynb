{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyasgune/sgune-ai/blob/main/A%20Beginner-Friendly%20PyTorch%20Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsoJitLznFM2"
      },
      "source": [
        "# A Beginner-Friendly PyTorch Tutorial: Build and Train Your First Model\n",
        "\n",
        "This is the accompanying notebook for my [blog post](https://huggingface.co/blog/dvgodoy/beginner-pytorch-tutorial) published on Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66d8mzvGi6_H"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FOVnFPsVifHv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data Generation\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1)\n",
        "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
        "\n",
        "# Shuffles the indices\n",
        "idx = np.arange(100)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:80]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[80:]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TvPfMK-i_kj"
      },
      "source": [
        "## Linear Regression in Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4f1mAxHi1Y-",
        "outputId": "336f4904-3b68-4048-e3a7-2154116523d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.49671415] [-0.1382643]\n",
            "[1.02354094] [1.96896411]\n",
            "[1.02354075] [1.96896447]\n"
          ]
        }
      ],
      "source": [
        "# Initializes parameters \"a\" and \"b\" randomly\n",
        "np.random.seed(42)\n",
        "a = np.random.randn(1)  # Line 3\n",
        "b = np.random.randn(1)  # Line 4\n",
        "\n",
        "print(a, b)\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 1e-1               # Line 9\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000         # Line 11\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Step 1: Computes our model's predicted output\n",
        "    yhat = a + b * x_train      # Line 15\n",
        "    # Step 2\n",
        "    # How wrong is our model? That's the error!\n",
        "    error = (y_train - yhat)    # Line 18\n",
        "    # It is a regression, so it computes mean squared error (MSE)\n",
        "    loss = (error ** 2).mean()  # Line 20\n",
        "    # Step 3\n",
        "    # Computes gradients for both \"a\" and \"b\" parameters\n",
        "    a_grad = -2 * error.mean()             # Line 23\n",
        "    b_grad = -2 * (x_train * error).mean() # Line 24\n",
        "    # Step 4\n",
        "    # Updates parameters using gradients and the learning rate\n",
        "    a = a - lr * a_grad   # Line 27\n",
        "    b = b - lr * b_grad   # Line 28\n",
        "\n",
        "print(a, b)\n",
        "\n",
        "# Sanity Check: do we get the same results as our gradient descent?\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linr = LinearRegression()\n",
        "linr.fit(x_train, y_train)\n",
        "print(linr.intercept_, linr.coef_[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESwCpz5ZjNOE"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcmOAg4OjQLu"
      },
      "source": [
        "### Loading Data, Devices, and CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W8qeUBhjW2_",
        "outputId": "086a6df8-7db3-4bdd-dbfa-89a7b9de7325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlihdzYojEvD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchviz import make_dot\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
        "# and then we send them to the chosen device\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
        "\n",
        "# Here we can see the difference - notice that .type() is more useful\n",
        "# since it also tells us WHERE the tensor is (device)\n",
        "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ks_I61je9_"
      },
      "source": [
        "### Creating Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NbiQg5pjZdY"
      },
      "outputs": [],
      "source": [
        "# We can specify the device at the moment of creation - RECOMMENDED!\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziyqFwVGjtcq"
      },
      "source": [
        "### Autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga1_qOLdjgpb"
      },
      "outputs": [],
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Step 1\n",
        "    yhat = a + b * x_train_tensor\n",
        "    # Step 2\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    # No more manual computation of gradients!\n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "\n",
        "    # Step 3\n",
        "    # We just tell PyTorch to work its way BACKWARDS from the specified loss!\n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    # print(a.grad)\n",
        "    # print(b.grad)\n",
        "\n",
        "    # What about UPDATING the parameters? Not so fast...\n",
        "\n",
        "    # FIRST ATTEMPT\n",
        "    # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
        "    # a = a - lr * a.grad\n",
        "    # b = b - lr * b.grad\n",
        "    # print(a)\n",
        "\n",
        "    # SECOND ATTEMPT\n",
        "    # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
        "    # a -= lr * a.grad\n",
        "    # b -= lr * b.grad\n",
        "\n",
        "    # THIRD ATTEMPT\n",
        "    # We need to use NO_GRAD to keep the update out of the gradient computation\n",
        "    # Why is that? It boils down to the DYNAMIC GRAPH that PyTorch uses...\n",
        "    # Step 4\n",
        "    with torch.no_grad():\n",
        "        a -= lr * a.grad\n",
        "        b -= lr * b.grad\n",
        "\n",
        "    # PyTorch is \"clingy\" to its computed gradients, we need to tell it to let it go...\n",
        "    a.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "print(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O71XydVnkFVG"
      },
      "source": [
        "### Dynamic Computation Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LDQKzFajw2V"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_sBv8BNkIJs"
      },
      "outputs": [],
      "source": [
        "from torchviz import make_dot\n",
        "parm_names = {'a': a, 'b': b, 'yhat': yhat, 'error': error, 'loss': loss}\n",
        "make_dot(yhat, parm_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXh-mvrmycIb"
      },
      "outputs": [],
      "source": [
        "make_dot(error, params=parm_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp-xlneNyeNj"
      },
      "outputs": [],
      "source": [
        "make_dot(loss, params=parm_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbHprOyhkOZt"
      },
      "outputs": [],
      "source": [
        "a_nograd = torch.randn(1, requires_grad=False, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "yhat2 = a_nograd + b * x_train_tensor\n",
        "parm_names = {'a_nograd': a_nograd, 'b': b, 'yhat2': yhat2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tti1f-DKkVgt"
      },
      "outputs": [],
      "source": [
        "make_dot(yhat2, params=parm_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOUwFucYzb4U"
      },
      "outputs": [],
      "source": [
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "if loss > 0:\n",
        "    yhat2 = b * x_train_tensor\n",
        "    error2 = y_train_tensor - yhat2\n",
        "loss += error2.mean()\n",
        "\n",
        "parm_names = {'a': a, 'b': b, 'yhat': yhat, 'error': error, 'loss': loss, 'yhat2': yhat2, 'error2': error2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLCJ692Fzvet"
      },
      "outputs": [],
      "source": [
        "make_dot(loss, params=parm_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovx0IFrYkg5_"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t728s9SjkXK5",
        "outputId": "54216a66-dd8a-41d1-e8c4-9dd7713d84ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Step 1\n",
        "    yhat = a + b * x_train_tensor\n",
        "    # Step 2\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "    # Step 3\n",
        "    loss.backward()\n",
        "\n",
        "    # No more manual update!\n",
        "    # with torch.no_grad():\n",
        "    #     a -= lr * a.grad\n",
        "    #     b -= lr * b.grad\n",
        "    # Step 4\n",
        "    optimizer.step()\n",
        "\n",
        "    # No more telling PyTorch to let gradients go!\n",
        "    # a.grad.zero_()\n",
        "    # b.grad.zero_()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "print(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjzWQc-oklGu"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL9ITaY8kiHk",
        "outputId": "19b3bf1d-e255-4f6b-eaee-d00db037065d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Step 1\n",
        "    yhat = a + b * x_train_tensor\n",
        "    # No more manual loss!\n",
        "    # error = y_tensor - yhat\n",
        "    # loss = (error ** 2).mean()\n",
        "    # Step 2\n",
        "    loss = loss_fn(y_train_tensor, yhat)   # Line 20\n",
        "    # Step 3\n",
        "    loss.backward()\n",
        "    # Step 4\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "print(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4v6oFczkoj4"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0yYXMlckl9k"
      },
      "outputs": [],
      "source": [
        "class ManualLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them with nn.Parameter\n",
        "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Computes the outputs / predictions\n",
        "        return self.a + self.b * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0jIy4nkqxp",
        "outputId": "3e9b0cff-5d8b-44e7-d696-5782cf7682c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([0.3367], device='cuda:0')), ('b', tensor([0.1288], device='cuda:0'))])\n",
            "OrderedDict([('a', tensor([1.0235], device='cuda:0')), ('b', tensor([1.9690], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = ManualLinearRegression().to(device)\n",
        "# We can also inspect its parameters using its state_dict\n",
        "print(model.state_dict())\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # What is this?!?\n",
        "    model.train()\n",
        "\n",
        "    # No more manual prediction!\n",
        "    # yhat = a + b * x_tensor\n",
        "    # Step 1\n",
        "    yhat = model(x_train_tensor)\n",
        "    # Step 2\n",
        "    loss = loss_fn(y_train_tensor, yhat)\n",
        "    # Step 3\n",
        "    loss.backward()\n",
        "    # Step 4\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nYXe9gKkv45"
      },
      "source": [
        "### Nested Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj0t9LiVkszp"
      },
      "outputs": [],
      "source": [
        "class LayerLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Instead of our custom parameters, we use a Linear layer with single input and single output\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Now it only takes a call to the layer to make predictions\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APQ7SBrRkzfn"
      },
      "source": [
        "### Sequential Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K9_9HWckw9t"
      },
      "outputs": [],
      "source": [
        "# Alternatively, you can use a Sequential model\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwcCLpKNk5t4"
      },
      "source": [
        "## Training Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I17f7bf0k0pL",
        "outputId": "49ee884e-d5ff-4fa2-ae6a-70fee9e9a3f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    # Builds function that performs a step in the train loop\n",
        "    def train_step(x, y):\n",
        "        # Sets model to TRAIN mode\n",
        "        model.train()\n",
        "        # Step 1: Makes predictions\n",
        "        yhat = model(x)\n",
        "        # Step 2: Computes loss\n",
        "        loss = loss_fn(y, yhat)\n",
        "        # Step 3: Computes gradients\n",
        "        loss.backward()\n",
        "        # Step 4: Updates parameters and zeroes gradients\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "\n",
        "    # Returns the function that will be called inside the train loop\n",
        "    return train_step\n",
        "\n",
        "# Starts from scratch\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "    # Performs one train step and returns the corresponding loss\n",
        "    loss = train_step(x_train_tensor, y_train_tensor)\n",
        "    losses.append(loss)\n",
        "\n",
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPJ1cE-Xk9w7"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt3E9uP4k8a0",
        "outputId": "faa5f95e-39f6-466a-f52b-3b3d63c039d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([0.7713]), tensor([2.4745]))\n",
            "(tensor([0.7713]), tensor([2.4745]))\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, TensorDataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        self.x = x_tensor\n",
        "        self.y = y_tensor\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])\n",
        "\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt6n0MxdlEJX"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNBv7ugtlAIi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YHcHWiclGWe",
        "outputId": "c30959af-eba4-463d-c648-6e787fa74202"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[0.1834],\n",
              "         [0.0452],\n",
              "         [0.8022],\n",
              "         [0.1395],\n",
              "         [0.7132],\n",
              "         [0.4722],\n",
              "         [0.0885],\n",
              "         [0.0055],\n",
              "         [0.6011],\n",
              "         [0.7320],\n",
              "         [0.5979],\n",
              "         [0.4952],\n",
              "         [0.8084],\n",
              "         [0.8324],\n",
              "         [0.3309],\n",
              "         [0.3745]]),\n",
              " tensor([[1.4637],\n",
              "         [0.9985],\n",
              "         [2.6229],\n",
              "         [1.3051],\n",
              "         [2.6162],\n",
              "         [1.9857],\n",
              "         [1.0708],\n",
              "         [1.0632],\n",
              "         [2.1214],\n",
              "         [2.4732],\n",
              "         [2.0407],\n",
              "         [1.8735],\n",
              "         [2.6141],\n",
              "         [2.6119],\n",
              "         [1.5427],\n",
              "         [1.7578]])]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XznZ_HJLlHlf",
        "outputId": "193ba889-45dd-4aad-a8b2-469bf504a19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9704]], device='cuda:0')), ('0.bias', tensor([1.0255], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "# Starts from scratch\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
        "        # therefore, we need to send those mini-batches to the\n",
        "        # device where the model \"lives\"\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtAnpMCxlShp"
      },
      "source": [
        "### Random Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LQPmf3xlJ_L"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BKRIKeqlVK_"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4uplL1slT_I",
        "outputId": "38c6a951-f3f7-46ff-8312-4849068bac8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9494]], device='cuda:0')), ('0.bias', tensor([1.0262], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "# Starts from scratch\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "losses = []\n",
        "val_losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            # Evaluation only performs Steps 1 and 2\n",
        "            model.eval()\n",
        "            # Step 1\n",
        "            yhat = model(x_val)              # Line 20\n",
        "            # Step 2\n",
        "            val_loss = loss_fn(y_val, yhat)  # Line 22\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2LHlyLTlXtA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}