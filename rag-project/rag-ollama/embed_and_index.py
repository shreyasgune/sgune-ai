# This  uses the faiss library to build an index on an array of embeddings generated by a sentence transformer model. The script also defines a function called embed which takes a text input and returns its embedding using the pre-trained Sentence Transformer model.

# The main purpose of this code is to build an index on the embeddings generated from the training data, so that we can perform efficient nearest neighbor search queries on them. The script uses the faiss library to create an index on the embeddings and then adds them to the index.

# The script also defines a function called build_faiss_index which takes an array of chunks as input, generates their embeddings using the embed function, and then creates an index on those embeddings using the faiss.IndexFlatL2 class. 

# The index is built on the CPU by default, but you can also build it on a GPU device by passing in a faiss.StandardGpuResources() object to the faiss.index_cpu_to_gpu function and specifying the GPU device id.

import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')
# model = model.to('cuda')

def embed(text):
    return model.encode(text, convert_to_numpy=True)

def build_faiss_index(chunks):
    embeddings = [embed(chunk) for chunk in chunks]
    dimension = len(embeddings[0])
    # res = faiss.StandardGpuResources()
    # index = faiss.index_cpu_to_gpu(res, 0, faiss.IndexFlatL2(dimension))
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings).astype('float32'))
    return index, chunks

